{"cells":[{"cell_type":"markdown","id":"4e98e551","metadata":{"id":"4e98e551"},"source":["# Importar os dados"]},{"cell_type":"code","execution_count":null,"id":"e504fdc3","metadata":{"id":"e504fdc3","outputId":"90d164a2-4d45-4d4c-f969-212c1ed23f02"},"outputs":[{"name":"stdout","output_type":"stream","text":["sentiment    48902\n","review       48902\n","dtype: int64\n","sentiment    2417\n","review       2417\n","dtype: int64\n"]}],"source":["import pandas as pd\n","\n","ds_test = pd.read_csv(r\"C:\\Users\\filip\\Desktop\\Mestrado\\2semestre\\TMCD\\Trabalho\\Dataset\\amazon_reviews_test.csv\")\n","ds_train = pd.read_csv(r\"C:\\Users\\filip\\Desktop\\Mestrado\\2semestre\\TMCD\\Trabalho\\Dataset\\amazon_reviews_train.csv\")\n","\n","print(ds_train.count())\n","print(ds_test.count())"]},{"cell_type":"markdown","id":"32e2904b","metadata":{"id":"32e2904b"},"source":["# MODELOS PRÉ-TREINADOS COM FINE-TUNING"]},{"cell_type":"markdown","id":"fb10602d","metadata":{"id":"fb10602d"},"source":["### siebert/sentiment-roberta-large-english"]},{"cell_type":"code","execution_count":null,"id":"84941b0b","metadata":{"id":"84941b0b","outputId":"154554a0-e496-4b3d-e56a-4f910a0fd719"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\filip\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset\n","from transformers import (\n","    RobertaForSequenceClassification,\n","    RobertaTokenizer,\n","    Trainer,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","import evaluate"]},{"cell_type":"code","execution_count":null,"id":"809af0d7","metadata":{"id":"809af0d7"},"outputs":[],"source":["model_name = \"siebert/sentiment-roberta-large-english\"\n","model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"id":"382c15cf","metadata":{"id":"382c15cf","outputId":"b2650515-ef07-43a2-8695-15456954a18f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 39121/39121 [00:02<00:00, 13193.67 examples/s]\n","Map: 100%|██████████| 9781/9781 [00:00<00:00, 13080.61 examples/s]\n"]}],"source":["ds_train['label'] = ds_train['sentiment'].map({'negative': 0, 'positive': 1})\n","\n","train_df, val_df = train_test_split(ds_train, test_size=0.2, stratify=ds_train['label'], random_state=42)\n","\n","train_dataset = Dataset.from_pandas(train_df[['review', 'label']])\n","val_dataset = Dataset.from_pandas(val_df[['review', 'label']])\n","\n","model_id = \"siebert/sentiment-roberta-large-english\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","def tokenize(batch):\n","    return tokenizer(batch[\"review\"], padding=\"max_length\", truncation=True, max_length=128)\n","\n","train_dataset = train_dataset.map(tokenize, batched=True)\n","val_dataset = val_dataset.map(tokenize, batched=True)\n","\n","train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"]},{"cell_type":"code","execution_count":null,"id":"4462a52c","metadata":{"id":"4462a52c"},"outputs":[],"source":["model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n","\n","for param in model.roberta.parameters():\n","    param.requires_grad = False\n"]},{"cell_type":"code","execution_count":null,"id":"32673e08","metadata":{"id":"32673e08"},"outputs":[],"source":["for name, param in model.named_parameters():\n","    if \"classifier\" in name:  # Deixe apenas a camada \"classifier\" com requires_grad=True\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False  # Congele todas as outras camadas"]},{"cell_type":"code","execution_count":null,"id":"8e2875fc","metadata":{"id":"8e2875fc"},"outputs":[],"source":["optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)"]},{"cell_type":"code","execution_count":null,"id":"8c3c03c1","metadata":{"id":"8c3c03c1"},"outputs":[],"source":["accuracy = evaluate.load(\"accuracy\")\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","    return {\"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]}"]},{"cell_type":"code","execution_count":null,"id":"af8dd6ea","metadata":{"id":"af8dd6ea"},"outputs":[],"source":["import torch\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,\n","    eval_strategy=\"steps\",\n","    eval_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    greater_is_better=True,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    fp16= torch.cuda.is_available(),\n","    gradient_accumulation_steps=10\n",")"]},{"cell_type":"code","execution_count":null,"id":"b84a7108","metadata":{"id":"b84a7108","outputId":"93c7a447-2562-48d9-e094-2ec8ea067cec"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_19136\\2408408702.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",")"]},{"cell_type":"code","execution_count":null,"id":"4bf05408","metadata":{"id":"4bf05408","outputId":"fcf051d6-80aa-4427-826b-5cedaea870bb"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='700' max='1956' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 700/1956 7:27:25 < 13:25:06, 0.03 it/s, Epoch 0/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.187200</td>\n","      <td>0.197911</td>\n","      <td>0.922298</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.214800</td>\n","      <td>0.191768</td>\n","      <td>0.922912</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.177300</td>\n","      <td>0.198305</td>\n","      <td>0.922912</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.229600</td>\n","      <td>0.192461</td>\n","      <td>0.923014</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.172400</td>\n","      <td>0.193725</td>\n","      <td>0.923832</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.196300</td>\n","      <td>0.199046</td>\n","      <td>0.923321</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.170200</td>\n","      <td>0.193055</td>\n","      <td>0.923627</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=700, training_loss=0.19458646348544528, metrics={'train_runtime': 26856.7942, 'train_samples_per_second': 2.913, 'train_steps_per_second': 0.073, 'total_flos': 6523519543296000.0, 'train_loss': 0.19458646348544528, 'epoch': 0.7156732440445762})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}